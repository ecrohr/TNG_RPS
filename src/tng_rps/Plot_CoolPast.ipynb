{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the figures for The Cooler Pasts paper\n",
    "## Written by Eric Rohr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import modules\n",
    "import illustris_python as il\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import ndimage\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import interpolate\n",
    "from tenet.util import sphMap\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import ks_2samp, anderson_ksamp\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import rohr_utils as ru \n",
    "import random\n",
    "import six\n",
    "%matplotlib widget\n",
    "\n",
    "plt.style.use('fullpage.mplstyle')\n",
    "\n",
    "zs, times = ru.return_zs_costimes()\n",
    "times /= 1.0e9 # [Gyr]\n",
    "scales = 1. / (1.+ zs)\n",
    "\n",
    "os.chdir('/u/reric/Scripts/')\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some plotting parameters\n",
    "figsizewidth  = 6.902 # the textwidth in inches of MNRAS\n",
    "figsizeratio = 9. / 16.\n",
    "figsizeheight = figsizewidth * figsizeratio\n",
    "\n",
    "figsizewidth_column = (244. / 508.) * figsizewidth\n",
    "figsizeheight_column = figsizewidth_column * figsizeratio\n",
    "\n",
    "outdirec_figures = '/u/reric/Figures/ColdPast/TNG-Cluster/'\n",
    "outdirec_overleaf = '/u/reric/Papers/Rohretal_TNG_CoolerPast/figures/'\n",
    "outdirecs = [outdirec_figures, outdirec_overleaf]\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some plotting functions that are useful everywhere\n",
    "def add_redshift_sincez2(ax, label=True, axislabel_kwargs=dict()):\n",
    "    \"\"\"\n",
    "    For a given x axis, add redshift since z=2 to the top x-axis. \n",
    "    Optionally label the axis + tick marks.\n",
    "    Returns ax\n",
    "    \"\"\"\n",
    "    ticks_SnapNum = [33, 40, 50, 59, 67, 78, 84, 91, 99]\n",
    "    ticks_costime = times[ticks_SnapNum]\n",
    "    ticks_labels = ['2', '1.5', '1', '0.7', '0.5', '0.3', '0.2', '0.1', '0']\n",
    "\n",
    "    xlolim = ru.floor_to_value(times[np.argmin(abs(zs - 2.5))], 0.1)\n",
    "    xhilim = ru.ceil_to_value(times[np.argmin(abs(zs - 0.0))], 0.1)\n",
    "    xhilim = 14.1\n",
    "\n",
    "    ax.set_xlim(xlolim, xhilim)\n",
    "\n",
    "    redshift_ax = ax.twiny()\n",
    "    redshift_ax.set_xlim(ax.get_xlim())\n",
    "    redshift_ax.set_xticks(ticks_costime)\n",
    "    redshift_ax.tick_params(axis='both', which='minor', top=False)\n",
    "    \n",
    "    yscale = ax.get_yscale()\n",
    "    if yscale == 'log':\n",
    "        locmin = mpl.ticker.LogLocator(subs=(0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9))\n",
    "        ax.yaxis.set_minor_locator(locmin)\n",
    "        #ax.yaxis.set_minor_formatter(mpl.ticker.NullFormatter())\n",
    "\n",
    "    if label:\n",
    "        redshift_ax.set_xlabel(r'Redshift', **axislabel_kwargs)\n",
    "        redshift_ax.set_xticklabels(ticks_labels)\n",
    "    else:\n",
    "        redshift_ax.set_xticklabels([])\n",
    "        \n",
    "    return ax\n",
    "\n",
    "\n",
    "def add_redshift_sincez5(ax, label=True, axislabel_kwargs=dict()):\n",
    "    \"\"\"\n",
    "    For a given x axis, add redshift since z=5 to the top x-axis. \n",
    "    Optionally label the axis + tick marks.\n",
    "    Returns ax\n",
    "    \"\"\"\n",
    "    ticks_SnapNum = [17, 33, 50, 67, 84, 99]\n",
    "    ticks_costime = times[ticks_SnapNum]\n",
    "    ticks_labels = ['5', '2', '1', '0.5', '0.2', '0']\n",
    "\n",
    "    xlolim = ru.floor_to_value(times[np.argmin(abs(zs - 5.5))], 0.1)\n",
    "    xlolim = 0.9\n",
    "    xhilim = ru.ceil_to_value(times[np.argmin(abs(zs - 0.0))], 0.1)\n",
    "    xhilim = 14.1\n",
    "\n",
    "    ax.set_xlim(xlolim, xhilim)\n",
    "\n",
    "    redshift_ax = ax.twiny()\n",
    "    redshift_ax.set_xlim(ax.get_xlim())\n",
    "    redshift_ax.set_xticks(ticks_costime)\n",
    "    redshift_ax.tick_params(axis='both', which='minor', top=False)\n",
    "    \n",
    "    yscale = ax.get_yscale()\n",
    "    if yscale == 'log':\n",
    "        locmin = mpl.ticker.LogLocator(subs=(0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9))\n",
    "        ax.yaxis.set_minor_locator(locmin)\n",
    "        #ax.yaxis.set_minor_formatter(mpl.ticker.NullFormatter())\n",
    "\n",
    "    if label:\n",
    "        redshift_ax.set_xlabel(r'Redshift', **axislabel_kwargs)\n",
    "        redshift_ax.set_xticklabels(ticks_labels)\n",
    "    else:\n",
    "        redshift_ax.set_xticklabels([])\n",
    "        \n",
    "    return ax\n",
    "\n",
    "\n",
    "def add_redshift_sincez7(ax, label=True, axislabel_kwargs=dict()):\n",
    "    \"\"\"\n",
    "    For a given x axis, add redshift since z=7 to the top x-axis. \n",
    "    Optionally label the axis + tick marks.\n",
    "    Returns ax\n",
    "    \"\"\"\n",
    "    ticks_SnapNum = [11, 21, 33, 50, 67, 84, 99]\n",
    "    ticks_costime = times[ticks_SnapNum]\n",
    "    ticks_labels = ['7', '4', '2', '1', '0.5', '0.2', '0']\n",
    "\n",
    "    xlolim = ru.floor_to_value(times[np.argmin(abs(zs - 7.5))], 0.1)\n",
    "    xlolim = 0.9\n",
    "    xhilim = ru.ceil_to_value(times[np.argmin(abs(zs - 0.0))], 0.1)\n",
    "    xhilim = 14.1\n",
    "\n",
    "    ax.set_xlim(xlolim, xhilim)\n",
    "\n",
    "    redshift_ax = ax.twiny()\n",
    "    redshift_ax.set_xlim(ax.get_xlim())\n",
    "    redshift_ax.set_xticks(ticks_costime)\n",
    "    redshift_ax.tick_params(axis='both', which='minor', top=False)\n",
    "    \n",
    "    yscale = ax.get_yscale()\n",
    "    if yscale == 'log':\n",
    "        locmin = mpl.ticker.LogLocator(subs=(0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9))\n",
    "        ax.yaxis.set_minor_locator(locmin)\n",
    "        #ax.yaxis.set_minor_formatter(mpl.ticker.NullFormatter())\n",
    "\n",
    "    if label:\n",
    "        redshift_ax.set_xlabel(r'Redshift', **axislabel_kwargs)\n",
    "        redshift_ax.set_xticklabels(ticks_labels)\n",
    "    else:\n",
    "        redshift_ax.set_xticklabels([])\n",
    "        \n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing functions for evolution quantities\n",
    "def noSmoothEvolution(group, xdset_key, ydset_key):\n",
    "    \"\"\" return xdset, ydset without any smoothing. Returns xdset, ydset \"\"\"\n",
    "    return group[xdset_key], group[ydset_key]\n",
    "\n",
    "\n",
    "def smoothSubhaloIndicesEvolution(group, xdset_key, ydset_key):\n",
    "    \"\"\" interpolate between where the subhalo is not defined. Returns xdset, ydset \"\"\"\n",
    "\n",
    "    subhalo_indices = group['SubfindID'] >= 0\n",
    "\n",
    "    _xdset = group[xdset_key][subhalo_indices]\n",
    "    _ydset = group[ydset_key][subhalo_indices]\n",
    "\n",
    "    ydset_func = interp1d(_xdset, _ydset, bounds_error=False, fill_value=0)\n",
    "\n",
    "    xdset = group[xdset_key]\n",
    "    ydset = ydset_func(xdset)\n",
    "\n",
    "    return xdset, ydset\n",
    "    \n",
    "\n",
    "def smoothRunningMedianEvolution(group, xdset_key, ydset_key, nRM=5):\n",
    "    \"\"\" \n",
    "    Compute the running median over nRM snapshots of ydset. \n",
    "    Assumes that y > 0 for all times. \n",
    "    Returns xdset, ydset.\n",
    "    \"\"\"\n",
    "    subhalo_indices = group['SubfindID'] >= 0\n",
    "    \n",
    "    _xdset = group[xdset_key][subhalo_indices]\n",
    "    _ydset = group[ydset_key][subhalo_indices]\n",
    "\n",
    "    mask = (_ydset > 0)\n",
    "\n",
    "    y_rm = ru.RunningMedian(_ydset[mask], 5)\n",
    "    ydset_func = interp1d(_xdset[mask], y_rm, bounds_error=False, fill_value=0)\n",
    "\n",
    "    xdset = group[xdset_key]\n",
    "    ydset = ydset_func(xdset)\n",
    "\n",
    "    return xdset, ydset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TNG-Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the gas radial profile dictionary\n",
    "grp_keys = ['SnapNum', 'SubfindID', 'CosmicTime', 'HostGroup_M_Crit200',\n",
    "            'HostGroup_R_Crit200', 'SubhaloMass', 'HostSubhaloGrNr',\n",
    "            'Subhalo_Mstar_Rgal', 'Subhalo_Rgal',\n",
    "            'SubhaloColdGasMass', 'SubhaloHotGasMass', 'SubhaloGasMass',\n",
    "            'radii', 'SubhaloColdGasMassShells',\n",
    "            'SubhaloCGMColdGasMass', 'SubhaloCGMColdGasFraction']\n",
    "\n",
    "def load_grpdict(infname, sim='L680n8192TNG', keys=None):\n",
    "    result = {}\n",
    "    with h5py.File('../Output/%s_subfindGRP/'%sim + infname, 'r') as f:\n",
    "        for group_key in f.keys():\n",
    "            result[group_key] = {}\n",
    "            if not keys:\n",
    "                keys = f[group_key].keys()\n",
    "            for dset_key in keys:\n",
    "                if 'xray' in dset_key:\n",
    "                    continue\n",
    "                if dset_key not in f[group_key]:\n",
    "                    continue\n",
    "                result[group_key][dset_key] = f[group_key][dset_key][:]\n",
    "        f.close()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# NB: the output file and directory are at L680n8192TNG, while all figures are saved as 'TNG-Cluster'\n",
    "sim = 'L680n8192TNG'\n",
    "\n",
    "infname = 'central_subfind_%s_branches.hdf5'%sim\n",
    "TNGCluster_grp_dict = load_grpdict(infname, sim)\n",
    "TNGCluster_grp_dict_keys = list(TNGCluster_grp_dict.keys())\n",
    "sim = 'TNG-Cluster'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the grp_dict into the tau_dict\n",
    "\n",
    "CGMColdGasMass_key = 'SubhaloCGMColdGasMass'\n",
    "fCGMColdGas_key = 'SubhaloCGMColdGasFraction'\n",
    "\n",
    "bh_mass_key = 'MainBHMass'\n",
    "bh_particleID_key = 'MainBHParticleID'\n",
    "BH_CumEgyInjection_RM_key = 'MainBH_CumEgyInjection_RM'\n",
    "BH_RM_FirstSnap_key = 'MainBH_RM_FirstSnap'\n",
    "\n",
    "Nsats_total_key = 'Nsatellites_total'\n",
    "Nsats_dr200_key = 'Nsatellites_dsathost<R200c'\n",
    "Nsats_mstar1e7_dr200c_key = 'Nsatellties_Mstar>1.0e7_dsathost<R200c'\n",
    "Nsats_mstar1e7_fgas_dr200c_key = 'NSatellites_Mstar>1.0e7_fgas>0.01_dsathost<R200c'\n",
    "Nsats_mstar1e9_dr200c_key = 'Nsatellties_Mstar>1.0e9_dsathost<R200c'\n",
    "Nsats_mstar1e9_fgas_dr200c_key = 'NSatellites_Mstar>1.0e9_fgas>0.01_dsathost<R200c'\n",
    "Nsats_mstar1e10_dr200c_key = 'NSatellites_Mstar>1.0e10_fgas>0.01_dsathost<R200c'\n",
    "Nsats_mstar1e10_fgas_dr200c_key = 'NSatellites_Mstar>1.0e10_fgas>0.01_dsathost<R200c'\n",
    "Nsats_mstar_1e7_SF_dr200c_key = 'NSatellites_Mstar>1.0e7_SF_dsathost<R200c'\n",
    "\n",
    "Nsats_keys = [Nsats_total_key, Nsats_dr200_key, \n",
    "              Nsats_mstar1e7_dr200c_key, Nsats_mstar1e7_fgas_dr200c_key,\n",
    "              Nsats_mstar1e9_dr200c_key, Nsats_mstar1e9_fgas_dr200c_key, \n",
    "              Nsats_mstar1e10_dr200c_key, Nsats_mstar1e10_fgas_dr200c_key,\n",
    "              Nsats_mstar_1e7_SF_dr200c_key]\n",
    "\n",
    "quench_snap_flag = -99\n",
    "bh_rm_firstsnap_flag = -100\n",
    "\n",
    "def create_taudict(grp_dict, snaps, branches_flag=False):\n",
    "    \"\"\" \n",
    "    Given the grp_dict and snaps of interest, rearrange the grp_dict\n",
    "    into a 2D array of the datasets at the snaps of interest. \n",
    "    snaps should be a list of snapNums, where snapNum -99 \n",
    "    is the flag to use the quenching_snap.\n",
    "    Returns the tau_dict.\n",
    "    \"\"\"\n",
    "    # input validation\n",
    "    if not isinstance(snaps, (list, np.ndarray)):\n",
    "        snaps = [snaps]\n",
    "\n",
    "    tau_keys = grp_keys.copy()\n",
    "    if branches_flag:\n",
    "        tau_keys.extend(Nsats_keys)\n",
    "                        \n",
    "    tauresult = {}\n",
    "    # begin loop over subhalos\n",
    "    for group_index, group_key in enumerate(grp_dict):\n",
    "        group = grp_dict[group_key]\n",
    "        # if just starting, then initialize the dictionary \n",
    "        if group_index == 0:\n",
    "            tauresult['SubfindID'] = np.zeros(len(grp_dict), dtype=int)\n",
    "            tauresult['HostSubhaloGrNr'] = np.zeros(len(grp_dict), dtype=int)\n",
    "            for tau_key in tau_keys:\n",
    "                if 'radii' in tau_key or 'Shells' in tau_key:\n",
    "                    continue\n",
    "                for snap in snaps:\n",
    "                    if snap == quench_snap_flag:\n",
    "                        tauresult_key = tau_key + '_snapNumQuench'\n",
    "                        tauresult[tauresult_key] = np.zeros(len(grp_dict),\n",
    "                                                            dtype=group[tau_key].dtype) - 1\n",
    "                    elif snap == bh_rm_firstsnap_flag:\n",
    "                        tauresult_key = tau_key + '_snapNumBHRMFirstSnap'\n",
    "                        tauresult[tauresult_key] = np.zeros(len(grp_dict),\n",
    "                                                            dtype=group[tau_key].dtype) - 1\n",
    "                    else:\n",
    "                        tauresult_key = tau_key + '_snapNum%03d'%snap\n",
    "                        tauresult[tauresult_key] = np.zeros(len(grp_dict),\n",
    "                                                            dtype=group[tau_key].dtype) - 1\n",
    "                    \n",
    "        tauresult['SubfindID'][group_index] = group['SubfindID'][0]\n",
    "        #tauresult['HostSubhaloGrNr'][group_index] = group['HostSubhaloGrNr'][0]\n",
    "        # finish initializing the the result\n",
    "        # assign the values at z=0, which are always the 0th element in the array\n",
    "        for tau_key in tau_keys:\n",
    "            if 'radii' in tau_key or 'Shells' in tau_key:\n",
    "                continue\n",
    "            for snap in snaps:\n",
    "                if snap == quench_snap_flag:\n",
    "                    tauresult_key = tau_key + '_snapNumQuench'\n",
    "                    tau_index = group['quenching_snap'] == group['SnapNum']\n",
    "                    tauresult[tauresult_key][group_index] = group[tau_key][tau_index]\n",
    "                elif snap == bh_rm_firstsnap_flag:\n",
    "                    tauresult_key = tau_key + '_snapNumBHRMFirstSnap'\n",
    "                    tau_index = group[BH_RM_FirstSnap_key] == group['SnapNum']\n",
    "                    tauresult[tauresult_key][group_index] = group[tau_key][tau_index]\n",
    "                else:\n",
    "                    tauresult_key = tau_key + '_snapNum%03d'%snap\n",
    "                    tau_index = snap == group['SnapNum']\n",
    "                    tauresult[tauresult_key][group_index] = group[tau_key][tau_index]\n",
    "                        \n",
    "            # finish loop over snaps for the grp_key\n",
    "        # finish grp_keys for the group\n",
    "    # finish loop over the groups\n",
    "    return tauresult\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TNGCluster_tau_dict = create_taudict(TNGCluster_grp_dict, [99, 67, 50, 33, bh_rm_firstsnap_flag], branches_flag=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: evolution of the cool ICM gas at the population level at fixed snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('Redshift_custom', ['k', 'tab:purple', 'tab:orange'])\n",
    "bounds = np.linspace(-0.5, 2.5, 4)\n",
    "bounds = np.array([-0.25, 0.25, 0.75, 3.25])\n",
    "cmap_norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "redshifts = [0.0, 0.5, 2.0]\n",
    "colors = ['k', 'tab:purple', 'tab:orange']\n",
    "\n",
    "def plot_stacked_temp_dict_evolution(ax, grp_dict, grp_dict_keys,\n",
    "                                     redshifts=redshifts, colors=colors, cmap=cmap, norm=cmap_norm,\n",
    "                                     return_color_dset='Redshift', color_dset_log=False):\n",
    "\n",
    "    ax, lc = add_stacked_temp_dict(ax, grp_dict, grp_dict_keys, redshifts=redshifts,\n",
    "                                   colors=colors, cmap=cmap, norm=norm, return_color_dset=return_color_dset, color_dset_log=color_dset_log)\n",
    "    ax.set_yscale('log')\n",
    "    cbar = fig.colorbar(lc, ax=ax, ticks=redshifts)\n",
    "    cbar.ax.set_yticklabels(['0', '0.5', '2'])\n",
    "    cbar.ax.minorticks_off()\n",
    "    cbar.solids.set(alpha=1.0)\n",
    "    cbar.set_label(r'Redshift', fontsize='small')\n",
    "\n",
    "    ax.set_ylabel(r'PDF', fontsize='small')\n",
    "    ax.set_xlabel(r'ICM Gas Temperature [log k]', fontsize='small')\n",
    "    ax.set_title(r'TNG-Cluster $M_{\\rm 200c}^{z=0}\\sim10^{15}\\, {\\rm M_\\odot}$ MPBs (%d)'%(len(grp_dict_keys)), fontsize='medium')\n",
    "\n",
    "    ax.set_ylim(3.0e-6, 5)\n",
    "    ax.set_xlim(2.75, 9.0)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "def add_stacked_temp_dict(ax, grp_dict, grp_dict_keys, redshifts=redshifts,\n",
    "                          bincents_key='CGMTemperaturesHistogramBincents', dset_key='CGMTemperaturesHistogram',\n",
    "                          colors=colors, cmap=cmap, norm=cmap_norm,\n",
    "                          return_color_dset='Redshift', color_dset_log=False):\n",
    "\n",
    "    result = {}\n",
    "    for redshift_i, redshift in enumerate(redshifts):\n",
    "        result[redshift] = {}\n",
    "        stacked_dict, bincents, hists, color = return_stacked_temp_dict(grp_dict, grp_dict_keys, return_all_profiles=True,\n",
    "                                                                        dset_key=dset_key, bincents_key=bincents_key,\n",
    "                                                                        redshift=redshift, return_color_dset=return_color_dset,\n",
    "                                                                        color_dset_log=color_dset_log)\n",
    "        result[redshift]['stacked_dict'] = stacked_dict\n",
    "        result[redshift]['bincents'] = bincents\n",
    "        result[redshift]['hists'] = hists\n",
    "        result[redshift]['color'] = color\n",
    "        result[redshift]['stacked_dict_kwargs'] = dict(path_effects=[pe.Stroke(linewidth=4, foreground='k'), pe.Normal()],\n",
    "                                                       marker='None', ls='-', lw=2, c=colors[redshift_i], label=r'$z=%d$'%(int(redshift)))\n",
    "        result[redshift]['norm_kwargs'] = dict(lw=0.1, alpha=0.5, ls='-', cmap=cmap, norm=norm)\n",
    "\n",
    "    for redshift_i, redshift in enumerate(redshifts[::-1]):\n",
    "        _result = result[redshift]\n",
    "        time_index = np.argmin(np.abs(grp_dict[grp_dict_keys[0]]['Redshift'] - redshift))\n",
    "\n",
    "        y = _result['stacked_dict']['50']\n",
    "        x = _result['stacked_dict']['bincents']\n",
    "        if 'Mass' in dset_key:\n",
    "            mask = y > 0\n",
    "        else: \n",
    "            mask = x > 0\n",
    "        ax.plot(x[mask], y[mask], **_result['stacked_dict_kwargs'])\n",
    "\n",
    "        _hists = _result['hists']\n",
    "        _bincents = _result['bincents']\n",
    "        ys = []\n",
    "        xs = []\n",
    "        cs = []\n",
    "        for y_i, y in enumerate(_hists):\n",
    "            if grp_dict[grp_dict_keys[y_i]]['SubfindID'][time_index] < 0:\n",
    "                continue\n",
    "            if 'Mass' in dset_key:\n",
    "                mask = y > 0\n",
    "            else: \n",
    "                mask = x > 0\n",
    "            x = _bincents[y_i][mask]\n",
    "            xs.append(x)\n",
    "            ys.append(y[mask])\n",
    "            cs.append(_result['color'][y_i])\n",
    "\n",
    "        if not norm:\n",
    "            vmin = np.percentile(cs, 5)\n",
    "            vmax = np.percentile(cs, 95)\n",
    "            if color_dset_log:\n",
    "                _result['norm_kwargs']['norm'] = mpl.colors.Normalize(vmin, vmax)\n",
    "            else:\n",
    "                _result['norm_kwargs']['norm'] = mpl.colors.LogNorm(vmin, vmax)\n",
    "        \n",
    "        lc = ru.multiline(xs, ys, cs, ax=ax, **_result['norm_kwargs'])\n",
    "\n",
    "    return ax, lc\n",
    "\n",
    "\n",
    "def return_stacked_temp_dict(grp_dict, grp_dict_keys, dset_key='CGMTemperaturesHistogram', bincents_key='CGMTemperaturesHistogramBincents',\n",
    "                             redshift=0., return_all_profiles=False, return_color_dset=False, color_dset_log=False):\n",
    "    \"\"\"\n",
    "    Given the grp_dict_keys and the implicit grp_dict, stack the dset_key for all of the\n",
    "    keys at the given time, which must match be either z0 or a tau definition, such as tau_infall_mass\n",
    "    \"\"\"\n",
    "        \n",
    "    result_dict = {}\n",
    " \n",
    "    # initalize the outputs\n",
    "    _bincents = np.zeros((len(grp_dict_keys), len(grp_dict[grp_dict_keys[0]][bincents_key][0])), dtype=float) - 1   \n",
    "    _hists = _bincents.copy() \n",
    "\n",
    "    if return_color_dset:\n",
    "        if return_color_dset in grp_dict[grp_dict_keys[0]].keys():\n",
    "            color_dset = np.zeros(len(grp_dict_keys), dtype=grp_dict[grp_dict_keys[0]][return_color_dset].dtype) - 1\n",
    "        else:\n",
    "            print('return_color_dset %s not recognized. Please choose from the following'%return_color_dset)\n",
    "            print(grp_dict[grp_dict_keys[0]].keys())\n",
    "            raise KeyError()\n",
    "\n",
    "    for index, grp_dict_key in enumerate(grp_dict_keys):\n",
    "        group = grp_dict[grp_dict_key]\n",
    "        time_index = np.argmin(abs(group['Redshift'] - redshift))\n",
    "        if group['SubfindID'][time_index] < 0:\n",
    "            continue\n",
    "        if return_color_dset:\n",
    "            if color_dset_log:\n",
    "                color_dset[index] = np.log10(group[return_color_dset][time_index])\n",
    "            else:\n",
    "                color_dset[index] = group[return_color_dset][time_index]\n",
    "        _bincents[index,:] = group[bincents_key][time_index]\n",
    "        _hist = group[dset_key][time_index]\n",
    "        if np.sum(_hist) <= 0:\n",
    "            continue\n",
    "        \n",
    "        if 'Temp' in dset_key:\n",
    "            _hists[index,:] = clean_temp_hist(_bincents[index,:], _hist, interp_zero=True, force_zero=True)\n",
    "        elif 'Mass' in dset_key:\n",
    "            result = compute_massext_profile(group, dset_key, time_index, norm='r200c')\n",
    "            _bincents[index,:] = result[0]\n",
    "            _hists[index,:] = result[1]\n",
    "\n",
    "    # finish loop of indices, save final results\n",
    "    bincents = np.ma.masked_values(_bincents, -1)\n",
    "    hists = np.ma.masked_values(_hists, -1)\n",
    "\n",
    "    result_dict['50'] = np.median(hists, axis=0)\n",
    "    result_dict['16'] = np.percentile(hists, 16, axis=0)\n",
    "    result_dict['84'] = np.percentile(hists, 84, axis=0) \n",
    "    result_dict['Ngal'] = len(hists)\n",
    "    result_dict['bincents'] = np.median(bincents, axis=0)\n",
    "    \n",
    "    if return_all_profiles:\n",
    "        if return_color_dset:\n",
    "            return result_dict, bincents, hists, color_dset\n",
    "        else:\n",
    "            return result_dict, bincents, hists\n",
    "    else:\n",
    "        if return_color_dset:\n",
    "            return result_dict, color_dset\n",
    "        else:\n",
    "            return result_dict\n",
    "\n",
    "def clean_temp_hist(bincents, hist, interp_zero=False, force_zero=False, rewrite_sfgas=False, normalize=True):\n",
    "    \"\"\"\n",
    "    clean the temperature histograms of artifacts, namely:\n",
    "    (1) interpolate zero-values between 10^4 K and maximum temperature\n",
    "    (2) overwrite temperatures between 10^3 and 10^4 K to be 0\n",
    "    (3) attribute SF gas to 10^4 K rather than 10^3 K\n",
    "    (4) Normalize the histogram to create a PDF\n",
    "    \"\"\"\n",
    "    _result = hist.copy()\n",
    "    binwidth = bincents[1] - bincents[0]\n",
    "    tolerance = 1.0e-1 # % of binwidth\n",
    "    if interp_zero:\n",
    "        bincents_mask = bincents > (4. - binwidth * tolerance)\n",
    "        zero_mask = hist <= 0\n",
    "        if _result[bincents_mask & ~zero_mask].size >= 2:\n",
    "            tempfunc = interp1d(bincents[bincents_mask & ~zero_mask], hist[bincents_mask & ~zero_mask], bounds_error=False, fill_value=0)\n",
    "            _result[bincents_mask & zero_mask] = tempfunc(bincents[bincents_mask & zero_mask])\n",
    "\n",
    "    if force_zero:\n",
    "        bincents_mask = ((bincents > (3. + binwidth * tolerance)) &\n",
    "                         (bincents < (4. - binwidth * tolerance)))\n",
    "        _result[bincents_mask] = 0\n",
    "\n",
    "    if rewrite_sfgas:\n",
    "        sf_mask = np.argmin(np.abs(bincents - 3.0))\n",
    "        rewrite_mask = np.argmin(np.abs(bincents - 4.0))\n",
    "        _result[rewrite_mask] = _result[sf_mask]\n",
    "        _result[sf_mask] = 0.\n",
    "\n",
    "    if normalize:\n",
    "        result = _result / np.sum(_result * binwidth)\n",
    "    else:\n",
    "        result = _result\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_dict = TNGCluster_grp_dict\n",
    "tau_dict = TNGCluster_tau_dict\n",
    "M200c_log = np.log10(tau_dict['HostGroup_M_Crit200_snapNum099'])\n",
    "mask = ((M200c_log > 14.95) * (M200c_log < 15.05))\n",
    "SubfindIDs = tau_dict['SubfindID'][mask]\n",
    "grp_dict_keys = []\n",
    "for subfindID in SubfindIDs:\n",
    "    grp_dict_keys.append('099_%08d'%subfindID)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = plot_stacked_temp_dict_evolution(ax, grp_dict, grp_dict_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3: MPBs of the all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_dict = TNGCluster_grp_dict\n",
    "tau_dict = TNGCluster_tau_dict\n",
    "maskdset_key = 'HostGroup_M_Crit200_snapNum099'\n",
    "maskdset_bincents = [14.4, 14.7, 15.0, 15.3]\n",
    "maskdset_binwidths = [0.1, 0.1, 0.1, 0.15]\n",
    "xdset_key = 'CosmicTime'\n",
    "ydset_key = 'HostGroup_M_Crit200'\n",
    "cdset_key = 'HostGroup_M_Crit200'\n",
    "smooth_func = smoothSubhaloIndicesEvolution\n",
    "\n",
    "cmap = 'viridis_r'\n",
    "cmap_norm = mpl.colors.Normalize(vmin=14.3, vmax=15.4)\n",
    "all_profiles_kwargs = dict(cmap=cmap, norm=cmap_norm, linewidths=0.1)\n",
    "stacked_profiles_kwargs = dict(cmap=cmap, norm=cmap_norm, linewidths=3, \n",
    "                               path_effects=[pe.Stroke(linewidth=4, foreground='white'), pe.Normal()])\n",
    "\n",
    "\n",
    "\n",
    "def plot_stacked_dict_evolution(ax, plot_result,\n",
    "                                all_profiles_kwargs=all_profiles_kwargs, stacked_profiles_kwargs=stacked_profiles_kwargs):\n",
    "    \"\"\"\n",
    "    plot all and stacked profiles from plot_result to ax\n",
    "    \"\"\"\n",
    "\n",
    "    lc = ru.multiline(plot_result['all_profiles']['xs'], plot_result['all_profiles']['ys'], plot_result['all_profiles']['cs'],\n",
    "                    ax=ax, **all_profiles_kwargs)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    cs = []\n",
    "    for bincent in plot_result['stacked_profiles']:\n",
    "        result_dict = plot_result['stacked_profiles'][bincent]\n",
    "        xs.append(result_dict['bincents'])\n",
    "        ys.append(result_dict['50'])\n",
    "        cs.append(float(bincent))\n",
    "\n",
    "    lc = ru.multiline(xs, ys, cs, ax=ax, **stacked_profiles_kwargs)\n",
    "\n",
    "    return ax, lc\n",
    "\n",
    "\n",
    "\n",
    "def return_stacked_dict_evolution(grp_dict=grp_dict, tau_dict=tau_dict,\n",
    "                                  maskdset_key=maskdset_key, maskdset_bincents=maskdset_bincents, maskdset_binwidths=maskdset_binwidths,\n",
    "                                  xdset_key=xdset_key, ydset_key=ydset_key, cdset_key=cdset_key, \n",
    "                                  smooth_func=smooth_func):\n",
    "    \"\"\" \n",
    "    Compute the evolution of ydset_key as a function of xdset_key, and compute the median evolution trend based on\n",
    "    the maskdset. Returns a dictionary plot_result which contains the necessary profiles to plot via ru.multiline()\n",
    "    both all profiles and the median trends. \n",
    "    \"\"\"\n",
    "\n",
    "    plot_result = dict(all_profiles=dict(), stacked_profiles=dict())\n",
    "\n",
    "    result_dict, result, color_dset = compute_stacked_dict_evolution(grp_dict, list(grp_dict.keys()),\n",
    "                                                                    smooth_func=smooth_func, ydset_key=ydset_key, xdset_key=xdset_key,\n",
    "                                                                    return_all_profiles=True, return_color_dset=cdset_key, color_dset_log=True)\n",
    "    ys = []\n",
    "    for row in np.arange(result.shape[0]):\n",
    "        ys.append(result[row])\n",
    "    xs = [result_dict['bincents'].tolist()] * len(ys)\n",
    "    cs = color_dset.tolist()\n",
    "\n",
    "    plot_result['all_profiles'] = dict(xs=xs, ys=ys, cs=cs, Ngal=len(xs))\n",
    "\n",
    "    SubfindIDz0 = tau_dict['SubfindID']\n",
    "\n",
    "    maskdset = tau_dict[maskdset_key]\n",
    "\n",
    "    maskdset_bincents = [14.4, 14.7, 15.0, 15.3]\n",
    "    maskdset_binwidths = [0.1, 0.1, 0.1, 0.15]\n",
    "    xs = []\n",
    "    ys = []\n",
    "    cs = []\n",
    "    for bincent_i, bincent in enumerate(maskdset_bincents):\n",
    "        maskdset_binwidth = maskdset_binwidths[bincent_i]\n",
    "        maskdset_lolim = 10.**(bincent - maskdset_binwidth)\n",
    "        maskdset_hilim = 10.**(bincent + maskdset_binwidth)\n",
    "\n",
    "        indices = np.where((maskdset > maskdset_lolim) & (maskdset < maskdset_hilim))[0]\n",
    "\n",
    "        grp_dict_keys = []\n",
    "        for index in indices:\n",
    "            grp_dict_keys.append('099_%08d'%SubfindIDz0[index])\n",
    "\n",
    "        result_dict = compute_stacked_dict_evolution(grp_dict, grp_dict_keys, xdset_key=xdset_key,\n",
    "                                                    smooth_func=smooth_func, ydset_key=ydset_key)\n",
    "        \n",
    "        plot_result['stacked_profiles'][bincent] = result_dict\n",
    "    \n",
    "    return plot_result\n",
    "\n",
    "\n",
    "def compute_stacked_dict_evolution(grp_dict, grp_dict_keys, xdset_key='CosmicTime', ydset_key=CGMColdGasMass_key,\n",
    "                                   smooth_func=noSmoothEvolution, return_all_profiles=False, return_color_dset=False, color_dset_log=False):\n",
    "    \"\"\"\n",
    "    Given the grp_dict and grp_dict_keys, stack the ydset_key for all of the\n",
    "    keys at xdset_key, where both xdset and ydset are scalars. Typically, xdset\n",
    "    should a time quantity, namely SnapNum, CosmicTime, or Redshift, although\n",
    "    any monotonically increasing (or decreasing) quantity is valid, such as \n",
    "    MainBH_CumEgyInjection_RM or maybe even HostGroup_M_Crit200. \n",
    "    Returns the resulting median + 16+84the percentils stacked dictionary,\n",
    "    plus optionally all profiles and a color dset. \n",
    "    \"\"\"\n",
    "    group0 = grp_dict[grp_dict_keys[0]]\n",
    "    xDSET = group0[xdset_key]\n",
    "        \n",
    "    result_dict = {}\n",
    " \n",
    "    # initalize the outputs\n",
    "    result = np.zeros((len(grp_dict_keys), len(xDSET)), dtype=group0[ydset_key].dtype) - 1.\n",
    "\n",
    "    if return_color_dset:\n",
    "        if return_color_dset in group0.keys():\n",
    "            color_dset = np.zeros(len(grp_dict_keys), dtype=group0[return_color_dset].dtype) - 1\n",
    "        else:\n",
    "            print('Error return_color_dset %s not available in'%return_color_dset, group0.keys())\n",
    "            raise ValueError\n",
    "\n",
    "    for index, grp_dict_key in enumerate(grp_dict_keys):\n",
    "        group = grp_dict[grp_dict_key]\n",
    "\n",
    "        xdset, ydset = smooth_func(group, xdset_key, ydset_key)\n",
    "\n",
    "        result[index,:] = ydset\n",
    "\n",
    "        if return_color_dset:\n",
    "            # assumes value of interest is at z=0, index, 0\n",
    "            if color_dset_log:\n",
    "                color_dset[index] = np.log10(group[return_color_dset][0])\n",
    "            else:\n",
    "                color_dset[index] = group[return_color_dset][0]\n",
    "        \n",
    "    # finish loop of indices, save final results\n",
    "    result = np.ma.masked_values(result, -1)\n",
    "    \n",
    "    result_dict['50'] = np.median(result, axis=0)\n",
    "    result_dict['16'] = np.percentile(result, 16, axis=0)\n",
    "    result_dict['84'] = np.percentile(result, 84, axis=0)\n",
    "    result_dict['Ngal'] = len(result)\n",
    "    result_dict['bincents'] = xdset \n",
    "    \n",
    "    if return_all_profiles:\n",
    "        if return_color_dset:\n",
    "            return result_dict, result, color_dset\n",
    "        else:\n",
    "            return result_dict, result\n",
    "    else:\n",
    "        if return_color_dset:\n",
    "            return result_dict, color_dset\n",
    "        else:\n",
    "            return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(figsizewidth_column, figsizeheight_column * 2.75))\n",
    "\n",
    "# top panel: M200c(t) vs t\n",
    "ax = axs[0]\n",
    "\n",
    "plot_result = return_stacked_dict_evolution()\n",
    "ax, lc = plot_stacked_dict_evolution(ax, plot_result)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax = add_redshift_sincez7(ax)\n",
    "ax.set_ylim(10.**(11), 10.**(15.7))\n",
    "\n",
    "ax.set_xlabel(r'Cosmic Time [Gyr]')\n",
    "ax.set_ylabel(r'Cluster Mass $[M_{\\rm 200c}(t) / {\\rm M_\\odot}]$')\n",
    "\n",
    "cax = inset_axes(ax, width='50%', height='10%', loc='lower right')\n",
    "cbar = plt.colorbar(lc, cax=cax, orientation='horizontal')\n",
    "cbar.set_label(r'$\\log_{10}[M_{\\rm 200c}^{z=0} / {\\rm M_\\odot}]$', fontsize='small', color='black')\n",
    "cbar.ax.tick_params(labelsize='small')\n",
    "cbar.set_ticks(maskdset_bincents)\n",
    "cax.xaxis.set_label_position('top')\n",
    "cax.xaxis.set_ticks_position('top')\n",
    "cbar.ax.minorticks_off()\n",
    "\n",
    "# bottom panel: M_CoolGas^ICM(t) vs t\n",
    "ax = axs[1]\n",
    "\n",
    "plot_result = return_stacked_dict_evolution(ydset_key=CGMColdGasMass_key, smooth_func=smoothRunningMedianEvolution)\n",
    "ax, _ = plot_stacked_dict_evolution(ax, plot_result)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax = add_redshift_sincez7(ax)\n",
    "ax.set_ylim(3e7, 7.0e11)\n",
    "\n",
    "ax.set_xlabel(r'Cosmic Time [Gyr]')\n",
    "ax.set_ylabel(r'Cool ICM Mass $[M_{\\rm CoolGas}^{\\rm ICM}(t) / {\\rm M_\\odot}]$')\n",
    "\n",
    "axs[0].set_title('TNG-Cluster Main Progenitors \\n' + r'$M_{\\rm 200c}^{z=0} \\sim 10^{14.3-15.4}\\, {\\rm M_\\odot}$ (352)')\n",
    "\n",
    "fname = '%s_M200ct_ICMCGMt_CosmicTime-Redshift_Evolution.pdf'%(sim)\n",
    "if savefig:\n",
    "    for outdirec in outdirecs:\n",
    "        fig.savefig(outdirec + fname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
