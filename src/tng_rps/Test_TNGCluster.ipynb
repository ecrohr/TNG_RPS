{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ab734",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import modules\n",
    "import illustris_python as il\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import h5py\n",
    "import rohr_utils as ru\n",
    "import os\n",
    "import yaml\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "class Configuration(dict):\n",
    "    \"\"\"\n",
    "    Class to store all relevant information for a given simulation and sample set.\n",
    "    \"\"\"\n",
    "    __slots__ = ()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_yaml(cls, fname):\n",
    "        \"\"\" Load from a yaml file. \"\"\"\n",
    "        with open(fname, 'r') as fin:\n",
    "            config = yaml.load(fin, yaml.SafeLoader)\n",
    "        return cls(config)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_str(cls, text: str):\n",
    "        \"\"\" Load from yaml-like string \"\"\"\n",
    "        config = yaml.load(text, yaml.SafeLoader)\n",
    "        return cls(config)\n",
    "    \n",
    "    def __getattr__(self, key):\n",
    "        \"\"\" Direct access as an attribute \"\"\"\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(key)\n",
    "            \n",
    "    def __setattr__(self, key, value):\n",
    "        \"\"\" Set additional attributes. \"\"\"\n",
    "        self[key] = value\n",
    "        return\n",
    "\n",
    "\n",
    "    def add_vals(self):\n",
    "        \"\"\" Add additional attributes \"\"\"\n",
    "        \n",
    "        #self = argparse_Config(self)\n",
    "        \n",
    "        self.basePath = ru.loadbasePath(self.sim)\n",
    "        self.outdirec, self.outfname = return_outdirec_outfname(self)\n",
    "        # for backwards compatibility\n",
    "        self.GRPfname = self.outfname\n",
    "        self.taufname = return_taufname(self)\n",
    "        \n",
    "        self.Header = il.groupcat.loadHeader(self.basePath, self.max_snap)\n",
    "        self.h = self.Header['HubbleParam']\n",
    "        \n",
    "        SnapNums = np.arange(self.max_snap, self.min_snap-1, -1)\n",
    "        Times = np.zeros(SnapNums.size, dtype=float)\n",
    "        BoxSizes = Times.copy()\n",
    "        for i, SnapNum in enumerate(SnapNums):\n",
    "            header = il.groupcat.loadHeader(self.basePath, SnapNum)\n",
    "            Times[i] = header['Time']\n",
    "            BoxSizes[i] = header['BoxSize'] * Times[i] / self.h\n",
    "        self.SnapNums = SnapNums\n",
    "        self.Times = Times\n",
    "        self.BoxSizes = BoxSizes\n",
    "        zs, cosmictimes = ru.timesfromsnap(self.basePath, SnapNums)\n",
    "        self.Redshifts = zs\n",
    "        self.CosmicTimes = cosmictimes / 1.0e9 # Gyr\n",
    "        \n",
    "        self.gas_ptn = il.util.partTypeNum('gas')\n",
    "        self.dm_ptn = il.util.partTypeNum('dm')\n",
    "        self.tracer_ptn = il.util.partTypeNum('tracer')\n",
    "        self.star_ptn = il.util.partTypeNum('star')\n",
    "        self.bh_ptn = il.util.partTypeNum('bh')\n",
    "        self.bary_ptns = [self.gas_ptn,\n",
    "                          self.star_ptn,\n",
    "                          self.bh_ptn]\n",
    "                          \n",
    "        self.Mstar_lolim = return_Mstar_lolim(self)\n",
    "        \n",
    "        # set the subfindIDs and accompanying snapnums of interest\n",
    "        # first check if the tau_dict already exists\n",
    "        full_taufname = self.outdirec + self.taufname\n",
    "        if (self.zooniverse_flag):\n",
    "            SnapNums_SubfindIDs, SubfindIDs = initialize_zooniverseindices(self)\n",
    "        elif os.path.isfile(full_taufname):\n",
    "            # yes, so just load the SubfindID (at z=0) for these\n",
    "            print('File %s exists. Using SubfindIDs and SnapNums from there.'%(full_taufname))\n",
    "            with h5py.File(full_taufname, 'r') as f:\n",
    "                Group = f['Group']\n",
    "                SubfindIDs = Group['SubfindID'][:]\n",
    "                SnapNums_SubfindIDs = np.zeros(SubfindIDs.size, dtype=int) + 99\n",
    "                f.close()\n",
    "        # does the GRP file exist? If so, then use this file. \n",
    "        # Note that this assumes that the branches exist at z=0\n",
    "        elif os.path.isfile(self.outdirec + self.GRPfname):\n",
    "            print('File %s exists. Using SubfindIDs and SnapNums from there.'%(self.outdirec + self.GRPfname))\n",
    "            with h5py.File(self.outdirec + self.GRPfname) as f:\n",
    "                SubfindIDs = np.zeros(len(f.keys()), dtype=int) - 1\n",
    "                SnapNums_SubfindIDs = SubfindIDs.copy() + 100\n",
    "                for i, key in enumerate(f.keys()):\n",
    "                    group = f[key]\n",
    "                    SubfindIDs[i] = group['SubfindID'][0]\n",
    "                f.close()\n",
    "            if np.min(SubfindIDs) < 0:\n",
    "                raise ValueError('Not all SubfindIDs are >=0 at z=0.')\n",
    "        # no tau or GRP files, so initialize SnapNums and SubfindIDs here\n",
    "        else:\n",
    "            # based on the simulation and flags, find the appropriate initialziation function\n",
    "            print('Files %s and %s do not exist. Initializing SubfindIDs and SnapNums elsewhere.'%(full_taufname,\n",
    "                                                                                                   self.outdirec + self.GRPfname))\n",
    "            # TNG-Cluster?\n",
    "            if (self.TNGCluster_flag):\n",
    "                SnapNums_SubfindIDs, SubfindIDs = initialize_TNGCluster_subfindindices(self)\n",
    "\n",
    "            # all centrals with M200c > 10.**(11.15)?\n",
    "            elif (self.centrals_flag):\n",
    "                SnapNums_SubfindIDs, SubfindIDs = initialize_central_subfindindices(self)\n",
    "                              \n",
    "            # all subhalos?\n",
    "            elif (self.allsubhalos_flag):\n",
    "                SnapNums_SubfindIDs, SubfindIDs = initialize_allsubhalos(self)\n",
    "              \n",
    "            # general satellites?\n",
    "            else:\n",
    "                SnapNums_SubfindIDs, SubfindIDs = initialize_subfindindices(self)\n",
    "                \n",
    "                \n",
    "        self.SubfindIDs = SubfindIDs\n",
    "        self.SnapNums_SubfindIDs = SnapNums_SubfindIDs\n",
    "\n",
    "        if self.tracers_flag:\n",
    "            if self.zooniverse_flag:\n",
    "                self.tracer_outdirec = '../Output/%s_tracers_zooniverse/'%(self.sim)\n",
    "            else:\n",
    "                self.tracer_outdirec = '../Output/%s_tracers/'%(self.sim)\n",
    "\n",
    "            if not os.path.isdir(self.tracer_outdirec):\n",
    "                print('Directory %s does not exist. Creating'%self.tracer_outdirec)\n",
    "                os.system('mkdir %s'%self.tracer_outdirec)\n",
    "            else:\n",
    "                print('Directory %s exists. Potentially overwriting files.'%self.tracer_outdirec)\n",
    "                \n",
    "        self.zooniverse_keys = [self.ins_key, self.jel_key, self.non_key]\n",
    "        self.subfindsnapshot_flags = [self.in_tree_key, self.central_key,\n",
    "                                      self.in_z0_host_key, self.host_m200c_key]\n",
    "        self.subfind_flags = [self.classified_flag, self.central_z0_flag,\n",
    "                              self.backsplash_z0_flag, self.backsplash_prev_flag,\n",
    "                              self.preprocessed_flag]\n",
    "                              \n",
    "        # tau dictionary keys\n",
    "        if self.centrals_flag:\n",
    "            self.taudict_keys = [self.all_key,\n",
    "                                 self.clean_key,\n",
    "                                 self.backsplash_z0_flag]\n",
    "        else:\n",
    "            self.taudict_keys = [self.backsplash_prev_flag,\n",
    "                                 self.preprocessed_flag,\n",
    "                                 self.clean_key]\n",
    "                \n",
    "        return\n",
    "\n",
    "\n",
    "def argparse_Config(Config):\n",
    "    \"\"\"\n",
    "    Parse all command line arguments and update them in the Config.\n",
    "    \"\"\"\n",
    "    description = ('Pipeline for running all analysis scripts related to \\n' +\n",
    "                   'computing the RSP in TNG galaxies.')\n",
    "    parser = argparse.ArgumentParser(description=description)\n",
    "    \n",
    "    # general flags\n",
    "    parser.add_argument('--sim', default=None, type=str,\n",
    "                        help='which simulation to use for the analysis.')\n",
    "    \n",
    "    parser.add_argument('--TNGCluster-flag', default=None, type=bool,\n",
    "                        help='analysis for TNG-Cluster')\n",
    "    parser.add_argument('--zooniverse-flag', default=None, type=bool,\n",
    "                        help='analysis using CJF zooniverse results')\n",
    "    parser.add_argument('--centrals-flag', default=None, type=bool,\n",
    "                        help='analysis for central galaxies')\n",
    "    parser.add_argument('--tracers-flag', default=None, type=bool,\n",
    "                        help='use tracer post-processing catalogs in analysis.')\n",
    "    parser.add_argument('--allsubhalos-flag', default=None, type=bool,\n",
    "                        help='use all subhalos in the simulation.')\n",
    "    # mp flags\n",
    "    parser.add_argument('--mp-flag', default=None, type=bool,\n",
    "                        help='use multiprocessing for analysis.')\n",
    "    parser.add_argument('--Nmpcores', default=None, type=int,\n",
    "                        help='Number of cores to use for multiprocessing tasks.')\n",
    "\n",
    "    # hard coded values\n",
    "    parser.add_argument('--max-snap', default=None, type=int,\n",
    "                        help='max snap for merger trees and analysis.')\n",
    "    parser.add_argument('--min-snap', default=None, type=int,\n",
    "                        help='min snap for merger trees and analysis.')\n",
    "    parser.add_argument('--first-snap', default=None, type=int,\n",
    "                        help='first snap for running the tracers.')\n",
    "    parser.add_argument('--last-snap', default=None, type=int,\n",
    "                        help='last snap for running the tracers.')\n",
    "    parser.add_argument('--tlim', default=None, type=float,\n",
    "                        help='temperature limit between cold and hot gas.')\n",
    "    parser.add_argument('--jellyscore-min', default=None, type=int,\n",
    "                        help='minimum score to be considered a jellyfish galaxy')\n",
    "\n",
    "    # which types of analysis should be run\n",
    "    parser.add_argument('--SubfindIndices', default=None, type=bool,\n",
    "                        help='flag to run Create_SubfindIndices.py.')\n",
    "    parser.add_argument('--SubfindGasRadProf', default=None, type=bool,\n",
    "                        help='flag to run Create_SubfindGasRadProf.py.')\n",
    "    parser.add_argument('--run-SGRP', default=None, type=bool,\n",
    "                        help='flag to run the main analysis in SubfindGasRadProf.py.')\n",
    "    parser.add_argument('--run-SGRP-PP', default=None, type=bool,\n",
    "                        help='flag to run the post processing of SGRP.')\n",
    "    parser.add_argument('--SubfindSnapshot', default=None, type=bool,\n",
    "                        help='flag to run Create_SubfindSnapshot_Flags.py.')\n",
    "    parser.add_argument('--run-SS', default=None, type=bool,\n",
    "                        help='flag to run main analysis in Create_SS_Flags.py.')\n",
    "    parser.add_argument('--run-SS-PP', default=None, type=bool,\n",
    "                        help='flag to run post-processing of Create_SS_Flags.py.')\n",
    "    parser.add_argument('--TracerTracks', default=None, type=bool,\n",
    "                        help='flag to run Create_TracerTracks.py.')\n",
    "    parser.add_argument('--track-tracers', default=None, type=bool,\n",
    "                        help='flag to run track_tracers().')\n",
    "    parser.add_argument('--find-tracers', default=None, type=bool,\n",
    "                        help='flag to run find_unmatched_tracers().')\n",
    "    parser.add_argument('--CleanSubfindGasRadProf', default=None, type=bool,\n",
    "                        help='flag to run Clean_SubfindGasRadProf.py.')\n",
    "    parser.add_argument('--run-cleanSGRP', default=None, type=bool,\n",
    "                        help='flag to run clean_subfindGRP().')\n",
    "    parser.add_argument('--run-createtau', default=None, type=bool,\n",
    "                        help='flag to run create_taudict().')\n",
    "\n",
    "    args = vars(parser.parse_args())\n",
    "    for key in args.keys():\n",
    "        if args[key]:\n",
    "            Config[key] = args[key]\n",
    "        \n",
    "    return Config\n",
    "                        \n",
    "\n",
    "def return_outdirec_outfname(Config):\n",
    "    \"\"\"\n",
    "    given the simulation and flags, determine the directory and GRP filename\n",
    "    \"\"\"\n",
    "    \n",
    "    outdirec = '../Output/%s_subfindGRP/'%Config.sim\n",
    "    if (Config.zooniverse_flag):\n",
    "        outfname = 'zooniverse_%s_%s_branches.hdf5'%(Config.sim, Config.zooniverse_key)\n",
    "        #outdirec = '../Output/zooniverse/'\n",
    "    elif Config.centrals_flag:\n",
    "        outfname = 'central_subfind_%s_branches.hdf5'%(Config.sim)\n",
    "    elif Config.allsubhalos_flag:\n",
    "        outfname = 'all_subfind_%s_branches.hdf5'%(Config.sim)\n",
    "    else:\n",
    "        outfname = 'subfind_%s_branches.hdf5'%(Config.sim)\n",
    "        \n",
    "    if (os.path.isdir(outdirec)):\n",
    "        print('Directory %s exists.'%outdirec)\n",
    "        if os.path.isfile(outdirec + outfname):\n",
    "            print('File %s exists. Overwriting.'%(outdirec+outfname))\n",
    "            return outdirec, outfname\n",
    "        else:\n",
    "            print('File %s does not exists. Writing.'%(outdirec+outfname))\n",
    "            return outdirec, outfname\n",
    "    else:\n",
    "        print('Directory %s does not exist. Creating it now.'%outdirec)\n",
    "        os.system('mkdir %s'%outdirec)\n",
    "        return outdirec, outfname\n",
    "        \n",
    "        \n",
    "def return_taufname(Config):\n",
    "    \"\"\" given the simulation and flags, determine the tau filename \"\"\"\n",
    "    if Config.zooniverse_flag:\n",
    "        return 'zooniverse_%s_%s_clean_tau.hdf5'%(Config.sim, Config.zooniverse_key)\n",
    "    elif Config.centrals_flag:\n",
    "        return 'central_subfind_%s_tau.hdf5'%(Config.sim)\n",
    "    elif Config.allsubhalos_flag:\n",
    "        return 'all_subfind_%s_clean_tau.hdf5'%(Config.sim)\n",
    "    else:\n",
    "        return 'subfind_%s_tau.hdf5'%(Config.sim)\n",
    "\n",
    "        \n",
    "def return_Mstar_lolim(Config):\n",
    "    \"\"\" given the simulation, determine the minimum resolved Mstar mass\"\"\"\n",
    "    sim = Config.sim\n",
    "    if 'TNG50' in sim:\n",
    "        res = 10.**(8.3)\n",
    "    elif 'TNG100' in sim:\n",
    "        res = 10.**(9.5)\n",
    "    elif 'TNG300' in sim:\n",
    "        res = 10.**(10)\n",
    "    elif 'L680n8192TNG' in sim:\n",
    "        return 10.**(10)\n",
    "    else:\n",
    "        raise ValueError('sim %s not recognized.'%sim)\n",
    "        \n",
    "    if sim == 'TNG50-4':\n",
    "        return 10.**(10)\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        if '-%d'%i in sim:\n",
    "            Mstar_lolim = res * 8**(i-1)\n",
    "            break\n",
    "        elif i == 4:\n",
    "            raise ValueError('sim %s not recongized.'%sim)\n",
    "            \n",
    "    return Mstar_lolim\n",
    " \n",
    "\n",
    "def initialize_allsubhalos(Config):\n",
    "    \"\"\"\n",
    "    Create a list of the subfindIDs for all subhalos in the simulation.\n",
    "    \"\"\"\n",
    "    \n",
    "    Nsubhalos = il.groupcat.loadSubhalos(Config.basePath, Config.max_snap, fields='SubhaloGrNr').size\n",
    "    SubfindIDs = np.arange(Nsubhalos)\n",
    "    SnapNums = np.ones(SubfindIDs.size, dtype=int) * 99\n",
    "    \n",
    "    return SnapNums, SubfindIDs\n",
    "    \n",
    "\n",
    "def initialize_subfindindices(Config):\n",
    "    \"\"\"\n",
    "    Define SubfindIDs and SnapNums to be tracked.\n",
    "    Returns all z=0 satellites with Mstar > Mstar_lolim\n",
    "    and SubhaloFlag == 1.\n",
    "    Returns SnapNums, SubfindIDs\n",
    "    \"\"\"\n",
    "    \n",
    "    basePath = Config.basePath\n",
    "    star_ptn = Config.star_ptn\n",
    "    Mstar_lolim = Config.Mstar_lolim\n",
    "    h = Config.h\n",
    "    \n",
    "    subhalo_fields = ['SubhaloFlag', 'SubhaloMassInRadType']\n",
    "    subhalos = il.groupcat.loadSubhalos(basePath, 99, fields=subhalo_fields)\n",
    "\n",
    "    halo_fields = ['GroupFirstSub']\n",
    "    GroupFirstSub = il.groupcat.loadHalos(basePath, 99, fields=halo_fields)\n",
    "\n",
    "    Mstar = subhalos['SubhaloMassInRadType'][:,star_ptn] * 1.0e10 / h\n",
    "    subfind_indices = np.where((subhalos['SubhaloFlag']) & (Mstar >= Mstar_lolim))[0]\n",
    "    indices = np.isin(subfind_indices, GroupFirstSub)\n",
    "    SubfindIDs = subfind_indices[~indices]\n",
    "    SnapNums = np.ones(SubfindIDs.size, dtype=int) * 99\n",
    "\n",
    "    return SnapNums, SubfindIDs\n",
    "\n",
    "\n",
    "def initialize_central_subfindindices(Config):\n",
    "    \"\"\"\n",
    "    Define SubfindIDs and SnapNums to be tracked.\n",
    "    Returns the most massive z=0 central subhalos.\n",
    "    \"\"\"\n",
    "    \n",
    "    halo_fields = ['Group_M_Crit200','GroupFirstSub']\n",
    "    halos = il.groupcat.loadHalos(Config.basePath, 99, fields=halo_fields)\n",
    "    M200c = halos['Group_M_Crit200'] * 1.0e10 / Config.h\n",
    "    indices = M200c >= 10.0**(11.5)\n",
    "\n",
    "    GroupFirstSub = halos['GroupFirstSub']\n",
    "    SubfindIDs = GroupFirstSub[indices]\n",
    "    SnapNums = np.ones(SubfindIDs.size, dtype=int) * 99\n",
    "\n",
    "    return SnapNums, SubfindIDs\n",
    "    \n",
    "    \n",
    "def initialize_TNGCluster_subfindindices(Config):\n",
    "    \"\"\"\n",
    "    Define the SubfindIDs at z=0 to be tracked.\n",
    "    \"\"\"\n",
    "    \n",
    "    basePath = Config.basePath\n",
    "    max_snap = Config.max_snap\n",
    "    star_ptn = Config.star_ptn\n",
    "    h = Config.h\n",
    "    Mstar_lolim = Config.Mstar_lolim\n",
    "    centrals_flag = Config.centrals_flag\n",
    "    \n",
    "    # load all halos and find the primary zoom target IDs\n",
    "    halo_fields = ['Group_M_Crit200', 'GroupFirstSub', 'GroupPrimaryZoomTarget']\n",
    "    halos = il.groupcat.loadHalos(basePath, max_snap, fields=halo_fields)\n",
    "    haloIDs = np.where(halos['GroupPrimaryZoomTarget'])[0]\n",
    "    GroupFirstSub = halos['GroupFirstSub'][haloIDs]\n",
    "    \n",
    "    print('There are %d primary zoom targets in %s.'%(haloIDs.size, Config.sim))\n",
    "    \n",
    "    # load all subhalos and find which ones:\n",
    "    # 1) are z=0 satellites of primary zooms\n",
    "    # 2) have Mstar(z=0) > Mstar_lolim\n",
    "    subhalo_fields = ['SubhaloGrNr', 'SubhaloMassInRadType']\n",
    "    subhalos = il.groupcat.loadSubhalos(basePath, max_snap, fields=subhalo_fields)\n",
    "    subhalo_indices_massive = subhalos['SubhaloMassInRadType'][:,star_ptn] * 1.0e10 / h > Mstar_lolim\n",
    "    \n",
    "    _, subhalo_match_indices = ru.match3(haloIDs, subhalos['SubhaloGrNr'][subhalo_indices_massive])\n",
    "    \n",
    "    # remove the central galaxies\n",
    "    subhaloIDs = np.where(subhalo_indices_massive)[0][subhalo_match_indices]\n",
    "    isin = np.isin(subhaloIDs, GroupFirstSub, assume_unique=True)\n",
    "    \n",
    "    if centrals_flag:\n",
    "        subfindIDs = subhaloIDs[isin]\n",
    "    else:\n",
    "        subfindIDs = subhaloIDs[~isin]\n",
    "        \n",
    "    snaps = np.ones(subfindIDs.size, dtype=subfindIDs.dtype) * max_snap\n",
    "    \n",
    "    return snaps, subfindIDs\n",
    "\n",
    "    \n",
    "def initialize_zooniverseindices(Config):\n",
    "    \"\"\"\n",
    "    Load all zooniverse output catalogs for the given simulation and determine\n",
    "    which galaxies have been inspected at multiple snapshots. Then tabulates the last\n",
    "    snapshot at which the galaxy was inspected, and the subfindID at that snapshot.\n",
    "    Returns SnapNums, SubfindIDs\n",
    "    \"\"\"\n",
    "    \n",
    "    indirec = '../IllustrisTNG/%s/postprocessing/Zooniverse_CosmologicalJellyfish/'%Config.sim\n",
    "    infname = 'jellyfish.hdf5'\n",
    "    \n",
    "    with h5py.File(indirec + infname, 'r') as inf:\n",
    "        snapnums = inf['Branches_SnapNum_LastInspect'][:]\n",
    "        subfindIDs = inf['Branches_SubfindID_LastInspect'][:]\n",
    "        \n",
    "        inf.close()\n",
    "    \n",
    "    return snapnums, subfindIDs\n",
    "\n",
    " \n",
    "    \n",
    "fname = 'config.yaml'\n",
    "config_dict = Configuration.from_yaml(fname)\n",
    "Config = Configuration(config_dict)\n",
    "Config.add_vals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import modules\n",
    "import illustris_python as il\n",
    "import numpy as np\n",
    "import h5py\n",
    "import rohr_utils as ru \n",
    "import os\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ae862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_result(Config):\n",
    "    \"\"\"\n",
    "    Initialize the result for a single subhalo\u0013.\n",
    "    \"\"\"\n",
    "    \n",
    "    keys = Config.subfindsnapshot_flags\n",
    "    \n",
    "    false_return = np.zeros(Config.SnapNums.size, dtype=int)\n",
    "    inval_return = false_return.copy() - 1\n",
    "    float_return = false_return.copy() - 1.\n",
    "\n",
    "    init_result = {}\n",
    "    for key in keys:\n",
    "        if key == Config.in_tree_key:\n",
    "            init_result[key] = false_return.copy()\n",
    "        elif key == Config.host_m200c_key:\n",
    "            init_result[key] = float_return.copy()\n",
    "        else:\n",
    "            init_result[key] = inval_return.copy()\n",
    "            \n",
    "    return init_result\n",
    "\n",
    "\n",
    "def return_outdirec_outfname(Config, snapshotflags=True):\n",
    "    \"\"\"\n",
    "    Helper function to determine the directory and filename for the outputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    outdirec = '../Output/%s_subfindsnapshotflags/'%(Config.sim)\n",
    "    if snapshotflags:\n",
    "        outfname = 'subfindsnapshot_flags.hdf5'\n",
    "    else:\n",
    "        outfname = 'subfind_flags.hdf5'\n",
    "\n",
    "    if (os.path.isdir(outdirec)):\n",
    "        print('Directory %s exists.'%outdirec)\n",
    "        if os.path.isfile(outdirec + outfname):\n",
    "            print('File %s exists. Overwriting.'%(outdirec+outfname))\n",
    "        else:\n",
    "            print('File %s does not exists. Writing.'%(outdirec+outfname))\n",
    "    else:\n",
    "        print('Directory %s does not exist. Creating it now.'%outdirec)\n",
    "        os.system('mkdir %s'%outdirec)\n",
    "    \n",
    "    return outdirec, outfname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_result(Config):\n",
    "    \"\"\"\n",
    "    Create a list of all subfindIDs of interest, namely those\n",
    "    defined in Create_SubfindIndices. However, we want to use the subfindID\n",
    "    as the index into the final result. So we create the result to be of size\n",
    "    all subfindIDs (with all -1 values), and later calculate the flags only\n",
    "    for the subhalos of interest.\n",
    "    \"\"\"\n",
    "    \n",
    "    subfindIDs = Config.SubfindIDs\n",
    "    if Config.zooniverse_flag:\n",
    "        grp_dict = h5py.File(Config.outdirec + Config.GRPfname, 'r')\n",
    "        SubfindIDs = []\n",
    "        for key in grp_dict.keys():\n",
    "            group = grp_dict[key]\n",
    "            indices = group['SubfindID'][:] != -1\n",
    "            if (group['SnapNum'][indices].max() == 99):\n",
    "                SubfindIDs.append(group['SubfindID'][0])\n",
    "        subfindIDs = np.array(SubfindIDs)\n",
    "        subfindIDs.sort()\n",
    "\n",
    "    SnapNums = Config.SnapNums\n",
    "    subfind_flags = Config.subfindsnapshot_flags\n",
    "    \n",
    "    # use the full catalog for the number of subhalos\n",
    "    Nsubhalos = il.groupcat.loadSubhalos(Config.basePath, Config.max_snap, fields='SubhaloGrNr').size\n",
    "    \n",
    "    # initlaize and fill finalize result\n",
    "    result = {}\n",
    "    # check if the files already exist, and if so, overwrite\n",
    "    subfindsnapshot_outdirec, subfindsnapshot_outfname = return_outdirec_outfname(Config, snapshotflags=True)\n",
    "    if os.path.isfile(subfindsnapshot_outdirec + subfindsnapshot_outfname):\n",
    "        with h5py.File(subfindsnapshot_outdirec + subfindsnapshot_outfname, 'r') as f:\n",
    "            group = f['group']\n",
    "            for key in group.keys():\n",
    "                result[key] = group[key][:]\n",
    "            f.close()\n",
    "        return subfindIDs, result\n",
    "\n",
    "    # file does not exist, so initialize result\n",
    "    for flag in subfind_flags:\n",
    "        if flag == Config.host_m200c_key:\n",
    "            result[flag] = np.zeros((Nsubhalos, SnapNums.size), dtype=float) - 1.\n",
    "        else:\n",
    "            result[flag] = np.zeros((Nsubhalos, SnapNums.size), dtype=int) - 1\n",
    "    \n",
    "    return subfindIDs, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # check the output directory and fname\n",
    "    subfindsnapshot_outdirec, subfindsnapshot_outfname = return_outdirec_outfname(Config, snapshotflags=True)\n",
    "            \n",
    "    # initialize the subfindIDs of interest and final result shape\n",
    "    subfindIDs, result = initialize_result(Config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.run_SS, Config.run_SS_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e37bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "        print('run_SS_PP: Number of subhalos of interest: %d'%subfindIDs.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d966457",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Nsnaps_PP = Config.Nsnaps_PP\n",
    "    M200c0_lolim_PP = Config.M200c0_lolim_PP\n",
    "\n",
    "    # load the catalogs\n",
    "    subfindsnapshot_outdirec, subfindsnapshot_outfname = return_outdirec_outfname(Config, snapshotflags=True)\n",
    "    f = h5py.File(subfindsnapshot_outdirec + subfindsnapshot_outfname, 'r')\n",
    "    group = f['group']\n",
    "\n",
    "    central_key = Config.central_key\n",
    "    in_tree_key = Config.in_tree_key\n",
    "    host_m200c_key = Config.host_m200c_key\n",
    "    in_z0_host_key = Config.in_z0_host_key\n",
    "    \n",
    "    classified_flag = Config.classified_flag\n",
    "    central_z0_flag = Config.central_z0_flag\n",
    "    backsplash_z0_flag = Config.backsplash_z0_flag\n",
    "    backsplash_prev_flag = Config.backsplash_prev_flag\n",
    "    preprocessed_flag = Config.preprocessed_flag\n",
    "    flags = Config.subfind_flags\n",
    "             \n",
    "    # initialize result\n",
    "    result = {}\n",
    "    # first check if the files already exist, and if so, append to them\n",
    "    subfindsnapshot_outdirec, subfindsnapshot_outfname = return_outdirec_outfname(Config, snapshotflags=False)\n",
    "    if os.path.isfile(subfindsnapshot_outdirec + subfindsnapshot_outfname):\n",
    "        with h5py.File(subfindsnapshot_outdirec + subfindsnapshot_outfname, 'r') as inf:\n",
    "            ingroup = inf['group']\n",
    "            for key in ingroup.keys():\n",
    "                result[key] = ingroup[key][:]\n",
    "            inf.close()\n",
    "    else:\n",
    "        for flag in flags:\n",
    "            result[flag] = np.zeros(len(group[in_tree_key]), dtype=int)\n",
    "            if flag != classified_flag:\n",
    "                result[flag] -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "subfindID = subfindIDs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # we only care about snapshots when the subhalo was identified in the merger trees\n",
    "        in_tree = group[in_tree_key][subfindID]\n",
    "        intree_indices = in_tree == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d121c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "intree_indices[intree_indices].size < Nsnaps_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        result[classified_flag][subfindID] = 1\n",
    "        \n",
    "        central = group[central_key][subfindID][intree_indices] == 1\n",
    "        in_z0_host = group[in_z0_host_key][subfindID][intree_indices] == 1\n",
    "        host_m200c = group[host_m200c_key][subfindID][intree_indices] >= M200c0_lolim_PP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e1462",
   "metadata": {},
   "outputs": [],
   "source": [
    "        if (central[0] == 1):\n",
    "            result[central_z0_flag][subfindID] = 1\n",
    "            # yes! Is the subhalo a backsplash galaxy?\n",
    "            backsplash_indices = ~central & ~in_z0_host & host_m200c\n",
    "            backsplash_check = [True] * Config.Nsnaps_PP\n",
    "            if (ru.is_slice_in_list(backsplash_check, backsplash_indices)):\n",
    "                result[backsplash_z0_flag][subfindID] = 1\n",
    "            else:\n",
    "                result[backsplash_z0_flag][subfindID] = 0\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[backsplash_z0_flag][subfindID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a6879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # no, the subhalo is a satellite at z=0\n",
    "        result[central_z0_flag][subfindID] = 0\n",
    "        # was the subhalo pre-processed?\n",
    "        preprocessed_indices = ~central & ~in_z0_host & host_m200c\n",
    "        preprocessed_check = [True] * Nsnaps_PP\n",
    "        if (ru.is_slice_in_list(preprocessed_check, preprocessed_indices)):\n",
    "            result[preprocessed_flag][subfindID] = 1\n",
    "        else:\n",
    "            result[preprocessed_flag][subfindID] = 0\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[preprocessed_flag][subfindID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # was the subhalo previously a backsplash?\n",
    "        # first, find the first time that the subhalo spent at least Nsnaps_PP in a massive host\n",
    "        satellite_indices = ~central & host_m200c\n",
    "        satellite_check = [True] * Nsnaps_PP\n",
    "        satellite_indices_bool = ru.where_is_slice_in_list(satellite_check, satellite_indices)\n",
    "        if any(satellite_indices_bool):\n",
    "            # from this first time that the subhalo was a satellite, find the index of\n",
    "            # the last conescutive snapshot.\n",
    "            end_index = np.where(satellite_indices_bool)[0].max()\n",
    "            \n",
    "            if end_index > 0:\n",
    "                # after this time, was the galaxy a central for at least Nsnaps_PP?\n",
    "                central_indices = central[:end_index]\n",
    "                central_check = [True]\n",
    "                if central_indices.size >= Nsnaps_PP:\n",
    "                    if ru.is_slice_in_list(central_check, central_indices):\n",
    "                        result[backsplash_prev_flag][subfindID] = 1\n",
    "        else:\n",
    "            result[backsplash_prev_flag][subfindID] = 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ebd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "any(satellite_indices_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[backsplash_prev_flag][subfindID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2026dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru.where_is_slice_in_list(satellite_check, satellite_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8623411",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([~central, host_m200c]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110b2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
